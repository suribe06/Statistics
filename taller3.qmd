---
title: Taller 3. Eduardo Avendano y Santiago Uribe
jupyter: python3
---

```{python}
import pandas as pd
import statsmodels.formula.api as smf
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
```

```{python}
df = pd.read_csv('baseball.csv')
df = df.drop('name', axis=1)
dim_df = df.shape
print(f"The dataset consists of {dim_df[0]} rows and {dim_df[1]} columns")
```

```{python}
df.dtypes
```

Let’s check how much missing data there is by columns

```{python}
# Missing values by column
df.isnull().sum()
```

Descriptive Statistics

```{python}
df.describe()
```

Histograms

```{python}
col_titles = ['Salary', 'Avg. Batting', 'On-Base Pct.', 'Runs', 'Hits', 'Doubles', 'Triples', 'Homeruns', 
               'Runs Batted In', 'Walks', 'Strikeouts', 'Stolen Bases', 'Errors']
fig, axs = plt.subplots(3, 5, figsize=(12,6))
axs = axs.ravel()
for i, col in enumerate(df.columns):
    axs[i].hist(df[col], edgecolor='black')
    axs[i].set_title(col_titles[i])
    
plt.tight_layout()
plt.show()
```

Boxplots

```{python}
import matplotlib.patches as mpatches

fliers = dict(markerfacecolor='m', marker='D') #atypical data
mean_ = dict(markerfacecolor='green', marker='D')
mean_artist = mpatches.Patch(facecolor='green', label='Mean')
ad_artist = mpatches.Patch(color='m', label='Atypical Data')

fig, axs = plt.subplots(3, 5, figsize=(12,6))
axs = axs.ravel()
for i, col in enumerate(df.columns):
  bp = axs[i].boxplot(df[col], vert=False, flierprops=fliers, showmeans=True, meanprops=mean_)
  axs[i].legend(handles=[mean_artist, ad_artist], loc='upper left', fontsize=8)
  axs[i].set_title(col_titles[i])

plt.tight_layout()
plt.show()
```

Correlation

```{python}
fig, ax = plt.subplots(figsize=(10, 10))
corr_matrix = df.corr()
corr_matrix = corr_matrix.rename(columns=dict(zip(corr_matrix.columns, col_titles)))
corr_matrix = corr_matrix.rename(index=dict(zip(corr_matrix.index, col_titles)))
sns.heatmap(corr_matrix, square=True, annot=True, ax=ax)
plt.show()
```

Normality Test for the data

```{python}
from scipy.stats import shapiro

for col in df.columns:
    data = df[col].tolist()
    stat, p = shapiro(data)
    ans = 'son normales' if p > 0.05 else 'no son normales'
    print(f'Los datos de la variable {col} {ans}')
```

# Linear Regression Model

Dataset split into train and test

```{python}
# Agregando una columna de unos para el intercepto
df = sm.add_constant(df)
```

```{python}
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df.drop('salary', axis=1), 
                                                    df['salary'], test_size=0.2, random_state=123)
```

```{python}
# Fitting the regression model
model = sm.OLS(y_train, X_train).fit()
print(model.summary())
```

```{python}
print('Coefficients LR')
print(model.params)
```

Significant variables for the model

```{python}
print('p-values variables')
print(model.pvalues)
```

Metrics to check the model

```{python}
from sklearn.metrics import mean_squared_error

y_test_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_test_pred)
print(f'MSE for the LR Model: {mse}')
```

El modelo de regresión lineal de todas las variables tiene un R-cuadrado ajustado de 0.445, lo que sugiere que alrededor del 44.5% de la variabilidad de la variable de respuesta (salario) puede explicarse por las variables predictoras incluidas en el modelo. 

Algunos de los coeficientes de regresión tienen p-valores altos, lo que sugiere que no son estadísticamente significativos. Por ejemplo, el coeficiente para "hits" tiene un p-valor de 0.936797, lo que sugiere que no es una variable significativa para predecir el salario. Además, la variable "RBI" tiene un p-valor marginalmente significativo (0.057780), lo que sugiere que puede ser una variable importante, pero se necesita más análisis para confirmar su importancia.

Con respecto al MSE, el valor obtenido indica que hay una alta varianza entre los valores predichos por el modelo y los valores reales de la variable objetivo. En otras palabras, el modelo no se ajusta bien a los datos y tiene un rendimiento insuficiente en la tarea de predicción. Esto puede ocurrir debido a que hay variables que estan muy correlacionadas, hay valores de 0.89 y 0.84

### Modelos Propuestos:

Seleccion de las mejores variables usando un enfoque voraz. En cada etapa, este estimador elige la mejor característica para añadir basándose en la puntuación de validación cruzada de un estimador.

```{python}
from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

df_copy = df.copy()
df_copy = df_copy.drop('const', axis=1)
X_train, X_test, y_train, y_test = train_test_split(df_copy.drop('salary', axis=1), 
                                                    df_copy['salary'], test_size=0.2, random_state=123)

# Model
model = LinearRegression().fit(X_train, y_train)
sfs = SequentialFeatureSelector(model, direction='forward', n_features_to_select=3)
sfs.fit(X_train, y_train)

# Variables seleccionadas
selected_features = X_train.columns[sfs.get_support()]
print("Variables seleccionadas:", selected_features)

# Entrenar el modelo con las variables seleccionadas
X_selected = X_train.iloc[:, sfs.get_support()]
model_final = LinearRegression().fit(X_selected, y_train)
coef_dict = dict(zip(X_selected.columns, model_final.coef_))
coef_dict['intercept'] = model_final.intercept_
print(coef_dict)
y_pred_selected = model_final.predict(X_test.iloc[:, sfs.get_support()])
mse_selected = mean_squared_error(y_test, y_pred_selected)
print(f"MSE del modelo con variables seleccionadas: {mse_selected}")
```

Quitando pares de variables con alta correlacion, hits-runs (0.89)

```{python}
df_copy = df.copy()
df_copy = df_copy.drop(['hits', 'runs'], axis=1)
X_train, X_test, y_train, y_test = train_test_split(df_copy.drop('salary', axis=1), 
                                                    df_copy['salary'], test_size=0.2, random_state=123)
model = sm.OLS(y_train, X_train).fit()
print(model.summary())
```

```{python}
y_test_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_test_pred)
print(f'MSE for the LR Model: {mse}')
```

Quitando pares de variables con alta correlacion, hits-runs (0.89) y dooubles-homeruns (0.84)

```{python}
df_copy = df.copy()
df_copy = df_copy.drop(['hits', 'runs', 'dooubles', 'homeruns'], axis=1)
X_train, X_test, y_train, y_test = train_test_split(df_copy.drop('salary', axis=1), 
                                                    df_copy['salary'], test_size=0.2, random_state=123)
model = sm.OLS(y_train, X_train).fit()
print(model.summary())
```

```{python}
y_test_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_test_pred)
print(f'MSE for the LR Model: {mse}')
```

Quitando pares de variables con alta correlacion, hits-runs (0.89) y OBP-batting (0.8)

```{python}
df_copy = df.copy()
df_copy = df_copy.drop(['hits', 'runs', 'OBP', 'batting'], axis=1)
X_train, X_test, y_train, y_test = train_test_split(df_copy.drop('salary', axis=1), 
                                                    df_copy['salary'], test_size=0.2, random_state=123)
model = sm.OLS(y_train, X_train).fit()
print(model.summary())
```

```{python}
y_test_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_test_pred)
print(f'MSE for the LR Model: {mse}')
```

Modelo eliminando las variables con mayor p-value del modelo completo:

```{python}
df_copy = df.copy()
df_copy = df_copy.drop(['hits', 'walks', 'OBP', 'batting'], axis=1)
X_train, X_test, y_train, y_test = train_test_split(df_copy.drop('salary', axis=1), 
                                                    df_copy['salary'], test_size=0.2, random_state=123)
model = sm.OLS(y_train, X_train).fit()
print(model.summary())
```

```{python}
y_test_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_test_pred)
print(f'MSE for the LR Model: {mse}')
```

Modelo teniendo en cuenta un analisis de PCA:

```{python}
from sklearn.decomposition import PCA

pca = PCA(n_components=13)
pca.fit(df.drop(['salary'], axis=1)) 
X_pca = pca.fit_transform(df.drop(['salary'], axis=1))

expl = pca.explained_variance_ratio_
print('suma:',sum(expl[0:5]))

plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.xticks(np.arange(0, df.shape[1]-1, 1.0))

plt.ylabel('cumulative explained variance')
plt.grid()
plt.show()
```

```{python}
X_pca_df = pd.DataFrame(X_pca[:, :5], columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])
X_pca_df['salary'] = df['salary']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_pca_df.drop('salary', axis=1), X_pca_df['salary'], test_size=0.2, random_state=123)
model = sm.OLS(y_train, X_train).fit()
print(model.summary())
```

```{python}
y_test_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_test_pred)
print(f'MSE for the LR Model: {mse}')
```

RESUMEN DE RESULTADOS

| Modelo                          | MSE          |
|---------------------------------|--------------|
| Modelo 2 elimnado correlaciones | 451,816.87   |
| Modelo sin p-values grandes     | 465,509.71   |
| Modelo Completo                 | 472,509.23   |
| Modelo 1 elimnado correlaciones | 488,929.62   |
| Modelo 3 elimnado correlaciones | 496,001.74   |
| Modelo Greedy                   | 500,367.14   |
| Modelo PCA                      | 6,045,180.40 |

# Punto 2

```{python}
df2 = pd.read_csv('fertility.csv')
df2 = df2.drop(['voc_train', 'german'], axis=1)
dim_df = df2.shape
print(f"The dataset consists of {dim_df[0]} rows and {dim_df[1]} columns")
```

```{python}
df2.isnull().sum()
```

Convert cathegorical data to numerical

```{python}
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
categorical_vars = ['university', 'religion', 'rural']
for var in categorical_vars:
    df2[var] = le.fit_transform(df2[var])
df2
```

```{python}
X_train = df2.drop('children', axis=1)
y_train = df2['children']
```

### Poisson Model

```{python}
model_poisson = sm.GLM(y_train, X_train, family=sm.families.Poisson()).fit()
print(model_poisson.summary())
```

Primeramente podemos hacer un analisis de significancia de las variables del modelo con respecto a su valor p. Como se puede ver en la tabla, todas las variables, excepto "religion" y "age_marriage", tienen valores p menores a 0.05, lo que indica que son estadísticamente significativas en el modelo. Por otro lado, como el valor p de "religion" y "age_marriage" son 0.119 > 0.05 y  0.066 > 0.05, respectivamente, no se puede afirmar que estas variable tengan un efecto significativo en el modelo.

El coeficiente negativo de "university", al ser una variable categorica binaria (si/no), sugiere que las mujeres con esta característica (es decir, un "si") tienen menos hijos.

Por otro lado, el coeficientes positivo de "rural" sugiere que las mujeres con estas caracteristica tienen mas hijos.

### Negative Binomial Model

Si la razón entre el Chi-cuadrado y los grados de libertad es mayor a 1, entonces existe sobredispersión.

En este caso, el Pearson Chi-cuadrado es de 1300, con 1237 grados de libertad, lo que resulta en una razón de 1.0509. Como esta razón es mayor a 1, se puede concluir que los datos presentan sobredispersión.

```{python}
model_nb = sm.GLM(y_train, X_train, family=sm.families.NegativeBinomial()).fit()
print(model_nb.summary())
```

Para comparar los 2 modelos usaremos el AIC (Akaike Information Criterion), que es un criterio de selección de modelos que busca equilibrar la complejidad del modelo con su capacidad para ajustarse a los datos. El AIC se calcula a partir del logaritmo de la función de verosimilitud del modelo y su complejidad. Cuanto menor sea el valor de AIC, mejor se ajustará el modelo a los datos. 

```{python}
# AIC y BIC del modelo Poisson
poisson_aic = model_poisson.aic
nb_aic = model_nb.aic
print("AIC Poisson:", poisson_aic)
print("AIC Binomial Negativo:", nb_aic)
```

Como se pueed apreciar, el modelo de Poisson es el que tiene menor AIC, por lo que es el modelo que mejor se ajusta a los datos.

Residuos

```{python}
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Definir los residuos del modelo Poisson
resid_poisson = model_poisson.resid_response

# Definir los residuos del modelo Binomial Negativo
resid_nb = model_nb.resid_response

plt.scatter(model_nb.fittedvalues, resid_nb, label='NB')
plt.scatter(model_poisson.fittedvalues, resid_poisson, label='Poisson')
plt.xlabel('Valores ajustados')
plt.ylabel('Residuos')
plt.legend()
plt.show()
```

```{python}
from scipy.stats import chi2

# Calcular la prueba de razón de verosimilitud
deg_free = model_nb.df_resid - model_poisson.df_resid  # Diferencia de grados de libertad
lr = -2 * (model_poisson.llf - model_nb.llf)  # Estadístico de la prueba
p = chi2.sf(lr, 1)  # Valor p

# Imprimir resultados
print("Chi-cuadrado:", lr)
print("Valor p:", p)
```

