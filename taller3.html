<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.306">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Taller 3. Eduardo Avendano y Santiago Uribe</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="taller3_files/libs/clipboard/clipboard.min.js"></script>
<script src="taller3_files/libs/quarto-html/quarto.js"></script>
<script src="taller3_files/libs/quarto-html/popper.min.js"></script>
<script src="taller3_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="taller3_files/libs/quarto-html/anchor.min.js"></script>
<link href="taller3_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="taller3_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="taller3_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="taller3_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="taller3_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Taller 3. Eduardo Avendano y Santiago Uribe</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'baseball.csv'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(<span class="st">'name'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>dim_df <span class="op">=</span> df.shape</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The dataset consists of </span><span class="sc">{</span>dim_df[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> rows and </span><span class="sc">{</span>dim_df[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> columns"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The dataset consists of 132 rows and 13 columns</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df.dtypes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>salary           int64
batting        float64
OBP            float64
runs             int64
hits             int64
dooubles         int64
tripes           int64
homeruns         int64
RBI              int64
walks            int64
strikeouts       int64
stolenbases      int64
errors           int64
dtype: object</code></pre>
</div>
</div>
<p>Let’s check how much missing data there is by columns</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Missing values by column</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df.isnull().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>salary         0
batting        0
OBP            0
runs           0
hits           0
dooubles       0
tripes         0
homeruns       0
RBI            0
walks          0
strikeouts     0
stolenbases    0
errors         0
dtype: int64</code></pre>
</div>
</div>
<p>Descriptive Statistics</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">salary</th>
<th data-quarto-table-cell-role="th">batting</th>
<th data-quarto-table-cell-role="th">OBP</th>
<th data-quarto-table-cell-role="th">runs</th>
<th data-quarto-table-cell-role="th">hits</th>
<th data-quarto-table-cell-role="th">dooubles</th>
<th data-quarto-table-cell-role="th">tripes</th>
<th data-quarto-table-cell-role="th">homeruns</th>
<th data-quarto-table-cell-role="th">RBI</th>
<th data-quarto-table-cell-role="th">walks</th>
<th data-quarto-table-cell-role="th">strikeouts</th>
<th data-quarto-table-cell-role="th">stolenbases</th>
<th data-quarto-table-cell-role="th">errors</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>2139.242424</td>
<td>0.260833</td>
<td>0.334364</td>
<td>57.431818</td>
<td>111.310606</td>
<td>19.598485</td>
<td>2.515152</td>
<td>12.454545</td>
<td>55.219697</td>
<td>45.803030</td>
<td>65.174242</td>
<td>8.962121</td>
<td>6.613636</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>1225.598699</td>
<td>0.037279</td>
<td>0.044794</td>
<td>27.614078</td>
<td>45.447920</td>
<td>9.941708</td>
<td>2.435378</td>
<td>10.373457</td>
<td>28.923514</td>
<td>24.351259</td>
<td>33.043459</td>
<td>12.094668</td>
<td>5.458585</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>109.000000</td>
<td>0.063000</td>
<td>0.063000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>2.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>1043.750000</td>
<td>0.243000</td>
<td>0.308750</td>
<td>37.000000</td>
<td>72.000000</td>
<td>12.000000</td>
<td>1.000000</td>
<td>3.000000</td>
<td>32.750000</td>
<td>28.000000</td>
<td>40.000000</td>
<td>2.000000</td>
<td>3.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>2179.000000</td>
<td>0.260500</td>
<td>0.338500</td>
<td>57.500000</td>
<td>113.000000</td>
<td>18.000000</td>
<td>2.000000</td>
<td>10.000000</td>
<td>50.000000</td>
<td>42.500000</td>
<td>60.500000</td>
<td>4.000000</td>
<td>5.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>2923.000000</td>
<td>0.285000</td>
<td>0.361500</td>
<td>77.250000</td>
<td>146.250000</td>
<td>27.000000</td>
<td>4.000000</td>
<td>19.000000</td>
<td>75.000000</td>
<td>59.000000</td>
<td>84.250000</td>
<td>11.000000</td>
<td>9.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>6100.000000</td>
<td>0.341000</td>
<td>0.424000</td>
<td>133.000000</td>
<td>216.000000</td>
<td>46.000000</td>
<td>13.000000</td>
<td>44.000000</td>
<td>133.000000</td>
<td>108.000000</td>
<td>175.000000</td>
<td>72.000000</td>
<td>31.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Histograms</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>col_titles <span class="op">=</span> [<span class="st">'Salary'</span>, <span class="st">'Avg. Batting'</span>, <span class="st">'On-Base Pct.'</span>, <span class="st">'Runs'</span>, <span class="st">'Hits'</span>, <span class="st">'Doubles'</span>, <span class="st">'Triples'</span>, <span class="st">'Homeruns'</span>, </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>               <span class="st">'Runs Batted In'</span>, <span class="st">'Walks'</span>, <span class="st">'Strikeouts'</span>, <span class="st">'Stolen Bases'</span>, <span class="st">'Errors'</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">6</span>))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>axs <span class="op">=</span> axs.ravel()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(df.columns):</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    axs[i].hist(df[col], edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    axs[i].set_title(col_titles[i])</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Boxplots</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.patches <span class="im">as</span> mpatches</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>fliers <span class="op">=</span> <span class="bu">dict</span>(markerfacecolor<span class="op">=</span><span class="st">'m'</span>, marker<span class="op">=</span><span class="st">'D'</span>) <span class="co">#atypical data</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>mean_ <span class="op">=</span> <span class="bu">dict</span>(markerfacecolor<span class="op">=</span><span class="st">'green'</span>, marker<span class="op">=</span><span class="st">'D'</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>mean_artist <span class="op">=</span> mpatches.Patch(facecolor<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Mean'</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>ad_artist <span class="op">=</span> mpatches.Patch(color<span class="op">=</span><span class="st">'m'</span>, label<span class="op">=</span><span class="st">'Atypical Data'</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">6</span>))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>axs <span class="op">=</span> axs.ravel()</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(df.columns):</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>  bp <span class="op">=</span> axs[i].boxplot(df[col], vert<span class="op">=</span><span class="va">False</span>, flierprops<span class="op">=</span>fliers, showmeans<span class="op">=</span><span class="va">True</span>, meanprops<span class="op">=</span>mean_)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  axs[i].legend(handles<span class="op">=</span>[mean_artist, ad_artist], loc<span class="op">=</span><span class="st">'upper left'</span>, fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  axs[i].set_title(col_titles[i])</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Correlation</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> df.corr()</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> corr_matrix.rename(columns<span class="op">=</span><span class="bu">dict</span>(<span class="bu">zip</span>(corr_matrix.columns, col_titles)))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> corr_matrix.rename(index<span class="op">=</span><span class="bu">dict</span>(<span class="bu">zip</span>(corr_matrix.index, col_titles)))</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr_matrix, square<span class="op">=</span><span class="va">True</span>, annot<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>ax)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Normality Test for the data</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> shapiro</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> df.columns:</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> df[col].tolist()</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    stat, p <span class="op">=</span> shapiro(data)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    ans <span class="op">=</span> <span class="st">'son normales'</span> <span class="cf">if</span> p <span class="op">&gt;</span> <span class="fl">0.05</span> <span class="cf">else</span> <span class="st">'no son normales'</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Los datos de la variable </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>ans<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Los datos de la variable salary no son normales
Los datos de la variable batting no son normales
Los datos de la variable OBP no son normales
Los datos de la variable runs son normales
Los datos de la variable hits son normales
Los datos de la variable dooubles no son normales
Los datos de la variable tripes no son normales
Los datos de la variable homeruns no son normales
Los datos de la variable RBI no son normales
Los datos de la variable walks no son normales
Los datos de la variable strikeouts no son normales
Los datos de la variable stolenbases no son normales
Los datos de la variable errors no son normales</code></pre>
</div>
</div>
<section id="linear-regression-model" class="level1">
<h1>Linear Regression Model</h1>
<p>Dataset split into train and test</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Agregando una columna de unos para el intercepto</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> sm.add_constant(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                                                    df[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting the regression model</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.509
Model:                            OLS   Adj. R-squared:                  0.445
Method:                 Least Squares   F-statistic:                     7.935
Date:                Wed, 03 May 2023   Prob (F-statistic):           5.68e-10
Time:                        21:21:38   Log-Likelihood:                -858.10
No. Observations:                 105   AIC:                             1742.
Df Residuals:                      92   BIC:                             1777.
Df Model:                          12                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const         610.4817    825.541      0.739      0.461   -1029.113    2250.077
batting      2222.3302   1.14e+04      0.195      0.846   -2.05e+04    2.49e+04
OBP         -1638.8541   8744.203     -0.187      0.852    -1.9e+04    1.57e+04
runs            7.3625     16.456      0.447      0.656     -25.321      40.046
hits            0.7794      9.802      0.080      0.937     -18.689      20.248
dooubles      -15.8879     19.852     -0.800      0.426     -55.316      23.541
tripes        -28.0621     51.604     -0.544      0.588    -130.552      74.428
homeruns       16.9401     28.594      0.592      0.555     -39.851      73.731
RBI            23.4869     12.224      1.921      0.058      -0.791      47.765
walks           2.7735     13.770      0.201      0.841     -24.575      30.122
strikeouts     -4.6099      4.667     -0.988      0.326     -13.879       4.659
stolenbases    14.9283     12.222      1.221      0.225      -9.345      39.202
errors        -19.7701     16.648     -1.188      0.238     -52.835      13.295
==============================================================================
Omnibus:                       12.536   Durbin-Watson:                   1.979
Prob(Omnibus):                  0.002   Jarque-Bera (JB):               13.938
Skew:                           0.715   Prob(JB):                     0.000941
Kurtosis:                       4.067   Cond. No.                     2.73e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.73e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Coefficients LR'</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.params)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Coefficients LR
const           610.481682
batting        2222.330221
OBP           -1638.854103
runs              7.362492
hits              0.779417
dooubles        -15.887854
tripes          -28.062148
homeruns         16.940114
RBI              23.486874
walks             2.773515
strikeouts       -4.609948
stolenbases      14.928319
errors          -19.770148
dtype: float64</code></pre>
</div>
</div>
<p>Significant variables for the model</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p-values variables'</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.pvalues)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>p-values variables
const          0.461490
batting        0.846156
OBP            0.851743
runs           0.655638
hits           0.936797
dooubles       0.425598
tripes         0.587896
homeruns       0.555018
RBI            0.057780
walks          0.840817
strikeouts     0.325847
stolenbases    0.225035
errors         0.238081
dtype: float64</code></pre>
</div>
</div>
<p>Metrics to check the model</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 472509.2342122604</code></pre>
</div>
</div>
<p>El modelo de regresión lineal de todas las variables tiene un R-cuadrado ajustado de 0.445, lo que sugiere que alrededor del 44.5% de la variabilidad de la variable de respuesta (salario) puede explicarse por las variables predictoras incluidas en el modelo.</p>
<p>Algunos de los coeficientes de regresión tienen p-valores altos, lo que sugiere que no son estadísticamente significativos. Por ejemplo, el coeficiente para “hits” tiene un p-valor de 0.936797, lo que sugiere que no es una variable significativa para predecir el salario. Además, la variable “RBI” tiene un p-valor marginalmente significativo (0.057780), lo que sugiere que puede ser una variable importante, pero se necesita más análisis para confirmar su importancia.</p>
<p>Con respecto al MSE, el valor obtenido indica que hay una alta varianza entre los valores predichos por el modelo y los valores reales de la variable objetivo. En otras palabras, el modelo no se ajusta bien a los datos y tiene un rendimiento insuficiente en la tarea de predicción. Esto puede ocurrir debido a que hay variables que estan muy correlacionadas, hay valores de 0.89 y 0.84</p>
<section id="modelos-propuestos" class="level3">
<h3 class="anchored" data-anchor-id="modelos-propuestos">Modelos Propuestos:</h3>
<p>Seleccion de las mejores variables usando un enfoque voraz. En cada etapa, este estimador elige la mejor característica para añadir basándose en la puntuación de validación cruzada de un estimador.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> SequentialFeatureSelector</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df.copy()</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df_copy.drop(<span class="st">'const'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df_copy.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>                                                    df_copy[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Model</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression().fit(X_train, y_train)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>sfs <span class="op">=</span> SequentialFeatureSelector(model, direction<span class="op">=</span><span class="st">'forward'</span>, n_features_to_select<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>sfs.fit(X_train, y_train)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Variables seleccionadas</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> X_train.columns[sfs.get_support()]</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Variables seleccionadas:"</span>, selected_features)</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenar el modelo con las variables seleccionadas</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>X_selected <span class="op">=</span> X_train.iloc[:, sfs.get_support()]</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>model_final <span class="op">=</span> LinearRegression().fit(X_selected, y_train)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>coef_dict <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(X_selected.columns, model_final.coef_))</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>coef_dict[<span class="st">'intercept'</span>] <span class="op">=</span> model_final.intercept_</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coef_dict)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>y_pred_selected <span class="op">=</span> model_final.predict(X_test.iloc[:, sfs.get_support()])</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>mse_selected <span class="op">=</span> mean_squared_error(y_test, y_pred_selected)</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE del modelo con variables seleccionadas: </span><span class="sc">{</span>mse_selected<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Variables seleccionadas: Index(['runs', 'tripes', 'homeruns'], dtype='object')
{'runs': 21.996696479214034, 'tripes': -57.43388406557736, 'homeruns': 32.45593597987061, 'intercept': 578.0977492624365}
MSE del modelo con variables seleccionadas: 500367.14098529215</code></pre>
</div>
</div>
<p>Quitando pares de variables con alta correlacion, hits-runs (0.89)</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df.copy()</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df_copy.drop([<span class="st">'hits'</span>, <span class="st">'runs'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df_copy.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>                                                    df_copy[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.507
Model:                            OLS   Adj. R-squared:                  0.454
Method:                 Least Squares   F-statistic:                     9.664
Date:                Wed, 03 May 2023   Prob (F-statistic):           6.62e-11
Time:                        21:21:38   Log-Likelihood:                -858.28
No. Observations:                 105   AIC:                             1739.
Df Residuals:                      94   BIC:                             1768.
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const         563.4073    805.423      0.700      0.486   -1035.778    2162.593
batting      5140.0797   7691.127      0.668      0.506   -1.01e+04    2.04e+04
OBP         -3691.6341   6589.876     -0.560      0.577   -1.68e+04    9392.719
dooubles      -12.4389     17.454     -0.713      0.478     -47.094      22.216
tripes        -14.8323     45.047     -0.329      0.743    -104.274      74.609
homeruns       21.4989     23.591      0.911      0.364     -25.342      68.339
RBI            24.3652     11.277      2.161      0.033       1.974      46.756
walks           8.0549      9.709      0.830      0.409     -11.223      27.333
strikeouts     -4.7943      4.427     -1.083      0.282     -13.585       3.997
stolenbases    19.5713      8.651      2.262      0.026       2.395      36.747
errors        -19.5004     16.334     -1.194      0.236     -51.932      12.931
==============================================================================
Omnibus:                       11.564   Durbin-Watson:                   1.947
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               12.487
Skew:                           0.685   Prob(JB):                      0.00194
Kurtosis:                       3.989   Cond. No.                     1.24e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.24e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 488929.61951423663</code></pre>
</div>
</div>
<p>Quitando pares de variables con alta correlacion, hits-runs (0.89) y dooubles-homeruns (0.84)</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df.copy()</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df_copy.drop([<span class="st">'hits'</span>, <span class="st">'runs'</span>, <span class="st">'dooubles'</span>, <span class="st">'homeruns'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df_copy.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>                                                    df_copy[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.500
Model:                            OLS   Adj. R-squared:                  0.458
Method:                 Least Squares   F-statistic:                     11.98
Date:                Wed, 03 May 2023   Prob (F-statistic):           1.03e-11
Time:                        21:21:38   Log-Likelihood:                -859.06
No. Observations:                 105   AIC:                             1736.
Df Residuals:                      96   BIC:                             1760.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const         510.0526    797.551      0.640      0.524   -1073.074    2093.179
batting      1469.4215   7021.885      0.209      0.835   -1.25e+04    1.54e+04
OBP         -1149.4606   6208.703     -0.185      0.854   -1.35e+04    1.12e+04
tripes        -25.7709     43.824     -0.588      0.558    -112.761      61.219
RBI            28.8328      6.412      4.496      0.000      16.104      41.561
walks           4.6577      9.150      0.509      0.612     -13.505      22.820
strikeouts     -2.9994      4.041     -0.742      0.460     -11.022       5.023
stolenbases    20.0057      8.558      2.338      0.021       3.018      36.993
errors        -18.9731     16.184     -1.172      0.244     -51.098      13.152
==============================================================================
Omnibus:                        8.148   Durbin-Watson:                   1.956
Prob(Omnibus):                  0.017   Jarque-Bera (JB):                7.774
Skew:                           0.603   Prob(JB):                       0.0205
Kurtosis:                       3.566   Cond. No.                     1.12e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.12e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 451816.86700758204</code></pre>
</div>
</div>
<p>Quitando pares de variables con alta correlacion, hits-runs (0.89) y OBP-batting (0.8)</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df.copy()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df_copy.drop([<span class="st">'hits'</span>, <span class="st">'runs'</span>, <span class="st">'OBP'</span>, <span class="st">'batting'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df_copy.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>                                                    df_copy[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.505
Model:                            OLS   Adj. R-squared:                  0.463
Method:                 Least Squares   F-statistic:                     12.22
Date:                Wed, 03 May 2023   Prob (F-statistic):           6.53e-12
Time:                        21:21:38   Log-Likelihood:                -858.53
No. Observations:                 105   AIC:                             1735.
Df Residuals:                      96   BIC:                             1759.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const         643.0386    265.933      2.418      0.017     115.167    1170.911
dooubles       -9.5105     16.723     -0.569      0.571     -42.706      23.685
tripes         -7.5679     43.311     -0.175      0.862     -93.540      78.404
homeruns       16.4791     22.207      0.742      0.460     -27.602      60.560
RBI            28.2745      9.593      2.947      0.004       9.233      47.316
walks           3.6807      5.216      0.706      0.482      -6.672      14.034
strikeouts     -5.2118      4.193     -1.243      0.217     -13.535       3.111
stolenbases    21.4778      8.106      2.650      0.009       5.388      37.568
errors        -18.2242     16.094     -1.132      0.260     -50.170      13.722
==============================================================================
Omnibus:                       10.198   Durbin-Watson:                   1.960
Prob(Omnibus):                  0.006   Jarque-Bera (JB):               10.555
Skew:                           0.641   Prob(JB):                      0.00510
Kurtosis:                       3.878   Cond. No.                         337.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 496001.73702509375</code></pre>
</div>
</div>
<p>Modelo eliminando las variables con mayor p-value del modelo completo:</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df.copy()</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df_copy.drop([<span class="st">'hits'</span>, <span class="st">'walks'</span>, <span class="st">'OBP'</span>, <span class="st">'batting'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df_copy.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>                                                    df_copy[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.508
Model:                            OLS   Adj. R-squared:                  0.467
Method:                 Least Squares   F-statistic:                     12.39
Date:                Wed, 03 May 2023   Prob (F-statistic):           4.74e-12
Time:                        21:21:39   Log-Likelihood:                -858.16
No. Observations:                 105   AIC:                             1734.
Df Residuals:                      96   BIC:                             1758.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const         638.8948    264.001      2.420      0.017     114.856    1162.933
runs           10.0074      9.188      1.089      0.279      -8.232      28.246
dooubles      -14.7123     16.905     -0.870      0.386     -48.269      18.844
tripes        -28.5430     46.473     -0.614      0.541    -120.792      63.706
homeruns       12.4897     21.779      0.573      0.568     -30.740      55.720
RBI            25.3140     10.201      2.481      0.015       5.065      45.563
strikeouts     -4.6401      3.924     -1.183      0.240     -12.429       3.149
stolenbases    14.4213     11.271      1.279      0.204      -7.952      36.795
errors        -19.0235     15.935     -1.194      0.235     -50.654      12.607
==============================================================================
Omnibus:                       11.750   Durbin-Watson:                   1.992
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               12.680
Skew:                           0.696   Prob(JB):                      0.00176
Kurtosis:                       3.979   Cond. No.                         350.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 465509.7083045767</code></pre>
</div>
</div>
<p>Modelo teniendo en cuenta un analisis de PCA:</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>pca.fit(df.drop([<span class="st">'salary'</span>], axis<span class="op">=</span><span class="dv">1</span>)) </span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(df.drop([<span class="st">'salary'</span>], axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>expl <span class="op">=</span> pca.explained_variance_ratio_</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'suma:'</span>,<span class="bu">sum</span>(expl[<span class="dv">0</span>:<span class="dv">5</span>]))</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>plt.plot(np.cumsum(pca.explained_variance_ratio_))</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'number of components'</span>)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="dv">0</span>, df.shape[<span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span>, <span class="fl">1.0</span>))</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'cumulative explained variance'</span>)</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>suma: 0.982670851047459</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-26-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>X_pca_df <span class="op">=</span> pd.DataFrame(X_pca[:, :<span class="dv">5</span>], columns<span class="op">=</span>[<span class="st">'PC1'</span>, <span class="st">'PC2'</span>, <span class="st">'PC3'</span>, <span class="st">'PC4'</span>, <span class="st">'PC5'</span>])</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>X_pca_df[<span class="st">'salary'</span>] <span class="op">=</span> df[<span class="st">'salary'</span>]</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_pca_df.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), X_pca_df[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                                 OLS Regression Results                                
=======================================================================================
Dep. Variable:                 salary   R-squared (uncentered):                   0.120
Model:                            OLS   Adj. R-squared (uncentered):              0.076
Method:                 Least Squares   F-statistic:                              2.738
Date:                Wed, 03 May 2023   Prob (F-statistic):                      0.0232
Time:                        21:21:39   Log-Likelihood:                         -960.29
No. Observations:                 105   AIC:                                      1931.
Df Residuals:                     100   BIC:                                      1944.
Df Model:                           5                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
PC1          -11.6002      3.481     -3.332      0.001     -18.507      -4.693
PC2            7.3171      7.948      0.921      0.359      -8.452      23.086
PC3            2.8853     11.678      0.247      0.805     -20.284      26.055
PC4          -18.1806     14.884     -1.221      0.225     -47.711      11.350
PC5           18.1515     23.822      0.762      0.448     -29.110      65.413
==============================================================================
Omnibus:                        4.621   Durbin-Watson:                   0.326
Prob(Omnibus):                  0.099   Jarque-Bera (JB):                4.509
Skew:                           0.506   Prob(JB):                        0.105
Kurtosis:                       2.927   Cond. No.                         6.86
==============================================================================

Notes:
[1] R² is computed without centering (uncentered) since the model does not contain a constant.
[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 6045180.400770556</code></pre>
</div>
</div>
<p>RESUMEN DE RESULTADOS</p>
<table class="table">
<thead>
<tr class="header">
<th>Modelo</th>
<th>MSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Modelo 2 elimnado correlaciones</td>
<td>451,816.87</td>
</tr>
<tr class="even">
<td>Modelo sin p-values grandes</td>
<td>465,509.71</td>
</tr>
<tr class="odd">
<td>Modelo Completo</td>
<td>472,509.23</td>
</tr>
<tr class="even">
<td>Modelo 1 elimnado correlaciones</td>
<td>488,929.62</td>
</tr>
<tr class="odd">
<td>Modelo 3 elimnado correlaciones</td>
<td>496,001.74</td>
</tr>
<tr class="even">
<td>Modelo Greedy</td>
<td>500,367.14</td>
</tr>
<tr class="odd">
<td>Modelo PCA</td>
<td>6,045,180.40</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="punto-2" class="level1">
<h1>Punto 2</h1>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_csv(<span class="st">'fertility.csv'</span>)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df2.drop([<span class="st">'voc_train'</span>, <span class="st">'german'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>dim_df <span class="op">=</span> df2.shape</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The dataset consists of </span><span class="sc">{</span>dim_df[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> rows and </span><span class="sc">{</span>dim_df[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> columns"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The dataset consists of 1243 rows and 7 columns</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>df2.isnull().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>children        0
years_school    0
university      0
religion        0
year_birth      0
rural           0
age_marriage    0
dtype: int64</code></pre>
</div>
</div>
<p>Convert cathegorical data to numerical</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>categorical_vars <span class="op">=</span> [<span class="st">'university'</span>, <span class="st">'religion'</span>, <span class="st">'rural'</span>]</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> var <span class="kw">in</span> categorical_vars:</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>    df2[var] <span class="op">=</span> le.fit_transform(df2[var])</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>df2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">children</th>
<th data-quarto-table-cell-role="th">years_school</th>
<th data-quarto-table-cell-role="th">university</th>
<th data-quarto-table-cell-role="th">religion</th>
<th data-quarto-table-cell-role="th">year_birth</th>
<th data-quarto-table-cell-role="th">rural</th>
<th data-quarto-table-cell-role="th">age_marriage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2</td>
<td>8</td>
<td>0</td>
<td>0</td>
<td>42</td>
<td>1</td>
<td>20</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>3</td>
<td>8</td>
<td>0</td>
<td>0</td>
<td>55</td>
<td>1</td>
<td>21</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2</td>
<td>8</td>
<td>0</td>
<td>0</td>
<td>51</td>
<td>1</td>
<td>24</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>8</td>
<td>0</td>
<td>0</td>
<td>54</td>
<td>0</td>
<td>26</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2</td>
<td>8</td>
<td>0</td>
<td>0</td>
<td>46</td>
<td>1</td>
<td>22</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1238</td>
<td>2</td>
<td>13</td>
<td>1</td>
<td>1</td>
<td>45</td>
<td>1</td>
<td>23</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1239</td>
<td>2</td>
<td>13</td>
<td>1</td>
<td>1</td>
<td>41</td>
<td>0</td>
<td>25</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1240</td>
<td>2</td>
<td>13</td>
<td>1</td>
<td>1</td>
<td>56</td>
<td>0</td>
<td>25</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1241</td>
<td>2</td>
<td>13</td>
<td>1</td>
<td>1</td>
<td>58</td>
<td>0</td>
<td>25</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1242</td>
<td>0</td>
<td>12</td>
<td>1</td>
<td>1</td>
<td>44</td>
<td>0</td>
<td>24</td>
</tr>
</tbody>
</table>

<p>1243 rows × 7 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> df2.drop(<span class="st">'children'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> df2[<span class="st">'children'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="poisson-model" class="level3">
<h3 class="anchored" data-anchor-id="poisson-model">Poisson Model</h3>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>model_poisson <span class="op">=</span> sm.GLM(y_train, X_train, family<span class="op">=</span>sm.families.Poisson()).fit()</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_poisson.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:               children   No. Observations:                 1243
Model:                            GLM   Df Residuals:                     1237
Model Family:                 Poisson   Df Model:                            5
Link Function:                    Log   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -2209.3
Date:                Wed, 03 May 2023   Deviance:                       1249.3
Time:                        21:21:39   Pearson chi2:                 1.30e+03
No. Iterations:                     4   Pseudo R-squ. (CS):           -0.03683
Covariance Type:            nonrobust                                         
================================================================================
                   coef    std err          z      P&gt;|z|      [0.025      0.975]
--------------------------------------------------------------------------------
years_school     0.0873      0.016      5.543      0.000       0.056       0.118
university      -0.3336      0.128     -2.599      0.009      -0.585      -0.082
religion        -0.0265      0.017     -1.551      0.121      -0.060       0.007
year_birth       0.0059      0.002      2.747      0.006       0.002       0.010
rural            0.1171      0.037      3.151      0.002       0.044       0.190
age_marriage    -0.0111      0.006     -1.836      0.066      -0.023       0.001
================================================================================</code></pre>
</div>
</div>
<p>Primeramente podemos hacer un analisis de significancia de las variables del modelo con respecto a su valor p.&nbsp;Como se puede ver en la tabla, todas las variables, excepto “religion” y “age_marriage”, tienen valores p menores a 0.05, lo que indica que son estadísticamente significativas en el modelo. Por otro lado, como el valor p de “religion” y “age_marriage” son 0.119 &gt; 0.05 y 0.066 &gt; 0.05, respectivamente, no se puede afirmar que estas variable tengan un efecto significativo en el modelo.</p>
<p>El coeficiente negativo de “university”, al ser una variable categorica binaria (si/no), sugiere que las mujeres con esta característica (es decir, un “si”) tienen menos hijos.</p>
<p>Por otro lado, el coeficientes positivo de “rural” sugiere que las mujeres con estas caracteristica tienen mas hijos.</p>
</section>
<section id="negative-binomial-model" class="level3">
<h3 class="anchored" data-anchor-id="negative-binomial-model">Negative Binomial Model</h3>
<p>Si la razón entre el Chi-cuadrado y los grados de libertad es mayor a 1, entonces existe sobredispersión.</p>
<p>En este caso, el Pearson Chi-cuadrado es de 1300, con 1237 grados de libertad, lo que resulta en una razón de 1.0509. Como esta razón es mayor a 1, se puede concluir que los datos presentan sobredispersión.</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>model_nb <span class="op">=</span> sm.GLM(y_train, X_train, family<span class="op">=</span>sm.families.NegativeBinomial()).fit()</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_nb.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:               children   No. Observations:                 1243
Model:                            GLM   Df Residuals:                     1237
Model Family:        NegativeBinomial   Df Model:                            5
Link Function:                    Log   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -2560.0
Date:                Wed, 03 May 2023   Deviance:                       429.50
Time:                        21:21:39   Pearson chi2:                     389.
No. Iterations:                     6   Pseudo R-squ. (CS):           -0.01113
Covariance Type:            nonrobust                                         
================================================================================
                   coef    std err          z      P&gt;|z|      [0.025      0.975]
--------------------------------------------------------------------------------
years_school     0.0877      0.029      2.991      0.003       0.030       0.145
university      -0.3324      0.227     -1.464      0.143      -0.777       0.113
religion        -0.0272      0.031     -0.867      0.386      -0.089       0.034
year_birth       0.0061      0.004      1.511      0.131      -0.002       0.014
rural            0.1100      0.068      1.620      0.105      -0.023       0.243
age_marriage    -0.0109      0.011     -0.985      0.325      -0.033       0.011
================================================================================</code></pre>
</div>
</div>
<p>Para comparar los 2 modelos usaremos el AIC (Akaike Information Criterion), que es un criterio de selección de modelos que busca equilibrar la complejidad del modelo con su capacidad para ajustarse a los datos. El AIC se calcula a partir del logaritmo de la función de verosimilitud del modelo y su complejidad. Cuanto menor sea el valor de AIC, mejor se ajustará el modelo a los datos.</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># AIC y BIC del modelo Poisson</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>poisson_aic <span class="op">=</span> model_poisson.aic</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>nb_aic <span class="op">=</span> model_nb.aic</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"AIC Poisson:"</span>, poisson_aic)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"AIC Binomial Negativo:"</span>, nb_aic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>AIC Poisson: 4430.502787480056
AIC Binomial Negativo: 5132.092370301076</code></pre>
</div>
</div>
<p>Como se pueed apreciar, el modelo de Poisson es el que tiene menor AIC, por lo que es el modelo que mejor se ajusta a los datos.</p>
<p>Residuos</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Definir los residuos del modelo Poisson</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>resid_poisson <span class="op">=</span> model_poisson.resid_response</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Definir los residuos del modelo Binomial Negativo</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>resid_nb <span class="op">=</span> model_nb.resid_response</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>plt.scatter(model_nb.fittedvalues, resid_nb, label<span class="op">=</span><span class="st">'NB'</span>)</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>plt.scatter(model_poisson.fittedvalues, resid_poisson, label<span class="op">=</span><span class="st">'Poisson'</span>)</span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Valores ajustados'</span>)</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Residuos'</span>)</span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-36-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chi2</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular la prueba de razón de verosimilitud</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>deg_free <span class="op">=</span> model_nb.df_resid <span class="op">-</span> model_poisson.df_resid  <span class="co"># Diferencia de grados de libertad</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="op">-</span><span class="dv">2</span> <span class="op">*</span> (model_poisson.llf <span class="op">-</span> model_nb.llf)  <span class="co"># Estadístico de la prueba</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> chi2.sf(lr, <span class="dv">1</span>)  <span class="co"># Valor p</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Imprimir resultados</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Chi-cuadrado:"</span>, lr)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Valor p:"</span>, p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chi-cuadrado: -701.5895828210196
Valor p: 1.0</code></pre>
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>