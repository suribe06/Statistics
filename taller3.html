<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.306">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Taller 3. Eduardo Avendano y Santiago Uribe</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="taller3_files/libs/clipboard/clipboard.min.js"></script>
<script src="taller3_files/libs/quarto-html/quarto.js"></script>
<script src="taller3_files/libs/quarto-html/popper.min.js"></script>
<script src="taller3_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="taller3_files/libs/quarto-html/anchor.min.js"></script>
<link href="taller3_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="taller3_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="taller3_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="taller3_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="taller3_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Taller 3. Eduardo Avendano y Santiago Uribe</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'baseball.csv'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(<span class="st">'name'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>dim_df <span class="op">=</span> df.shape</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The dataset consists of </span><span class="sc">{</span>dim_df[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> rows and </span><span class="sc">{</span>dim_df[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> columns"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The dataset consists of 132 rows and 13 columns</code></pre>
</div>
</div>
<p>Data types of the columns:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df.dtypes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>salary           int64
batting        float64
OBP            float64
runs             int64
hits             int64
dooubles         int64
tripes           int64
homeruns         int64
RBI              int64
walks            int64
strikeouts       int64
stolenbases      int64
errors           int64
dtype: object</code></pre>
</div>
</div>
<p>Let’s check how much missing data there is by columns</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Missing values by column</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df.isnull().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>salary         0
batting        0
OBP            0
runs           0
hits           0
dooubles       0
tripes         0
homeruns       0
RBI            0
walks          0
strikeouts     0
stolenbases    0
errors         0
dtype: int64</code></pre>
</div>
</div>
<p>Descriptive Statistics</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">salary</th>
<th data-quarto-table-cell-role="th">batting</th>
<th data-quarto-table-cell-role="th">OBP</th>
<th data-quarto-table-cell-role="th">runs</th>
<th data-quarto-table-cell-role="th">hits</th>
<th data-quarto-table-cell-role="th">dooubles</th>
<th data-quarto-table-cell-role="th">tripes</th>
<th data-quarto-table-cell-role="th">homeruns</th>
<th data-quarto-table-cell-role="th">RBI</th>
<th data-quarto-table-cell-role="th">walks</th>
<th data-quarto-table-cell-role="th">strikeouts</th>
<th data-quarto-table-cell-role="th">stolenbases</th>
<th data-quarto-table-cell-role="th">errors</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
<td>132.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>2139.242424</td>
<td>0.260833</td>
<td>0.334364</td>
<td>57.431818</td>
<td>111.310606</td>
<td>19.598485</td>
<td>2.515152</td>
<td>12.454545</td>
<td>55.219697</td>
<td>45.803030</td>
<td>65.174242</td>
<td>8.962121</td>
<td>6.613636</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>1225.598699</td>
<td>0.037279</td>
<td>0.044794</td>
<td>27.614078</td>
<td>45.447920</td>
<td>9.941708</td>
<td>2.435378</td>
<td>10.373457</td>
<td>28.923514</td>
<td>24.351259</td>
<td>33.043459</td>
<td>12.094668</td>
<td>5.458585</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>109.000000</td>
<td>0.063000</td>
<td>0.063000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>2.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>1043.750000</td>
<td>0.243000</td>
<td>0.308750</td>
<td>37.000000</td>
<td>72.000000</td>
<td>12.000000</td>
<td>1.000000</td>
<td>3.000000</td>
<td>32.750000</td>
<td>28.000000</td>
<td>40.000000</td>
<td>2.000000</td>
<td>3.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>2179.000000</td>
<td>0.260500</td>
<td>0.338500</td>
<td>57.500000</td>
<td>113.000000</td>
<td>18.000000</td>
<td>2.000000</td>
<td>10.000000</td>
<td>50.000000</td>
<td>42.500000</td>
<td>60.500000</td>
<td>4.000000</td>
<td>5.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>2923.000000</td>
<td>0.285000</td>
<td>0.361500</td>
<td>77.250000</td>
<td>146.250000</td>
<td>27.000000</td>
<td>4.000000</td>
<td>19.000000</td>
<td>75.000000</td>
<td>59.000000</td>
<td>84.250000</td>
<td>11.000000</td>
<td>9.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>6100.000000</td>
<td>0.341000</td>
<td>0.424000</td>
<td>133.000000</td>
<td>216.000000</td>
<td>46.000000</td>
<td>13.000000</td>
<td>44.000000</td>
<td>133.000000</td>
<td>108.000000</td>
<td>175.000000</td>
<td>72.000000</td>
<td>31.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Histograms</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>col_titles <span class="op">=</span> [<span class="st">'Salary'</span>, <span class="st">'Avg. Batting'</span>, <span class="st">'On-Base Pct.'</span>, <span class="st">'Runs'</span>, <span class="st">'Hits'</span>, <span class="st">'Doubles'</span>, <span class="st">'Triples'</span>, <span class="st">'Homeruns'</span>, </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>               <span class="st">'Runs Batted In'</span>, <span class="st">'Walks'</span>, <span class="st">'Strikeouts'</span>, <span class="st">'Stolen Bases'</span>, <span class="st">'Errors'</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">6</span>))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>axs <span class="op">=</span> axs.ravel()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(df.columns):</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    axs[i].hist(df[col], edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    axs[i].set_title(col_titles[i])</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Boxplots</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.patches <span class="im">as</span> mpatches</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>fliers <span class="op">=</span> <span class="bu">dict</span>(markerfacecolor<span class="op">=</span><span class="st">'m'</span>, marker<span class="op">=</span><span class="st">'D'</span>) <span class="co">#atypical data</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>mean_ <span class="op">=</span> <span class="bu">dict</span>(markerfacecolor<span class="op">=</span><span class="st">'green'</span>, marker<span class="op">=</span><span class="st">'D'</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>mean_artist <span class="op">=</span> mpatches.Patch(facecolor<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Mean'</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>ad_artist <span class="op">=</span> mpatches.Patch(color<span class="op">=</span><span class="st">'m'</span>, label<span class="op">=</span><span class="st">'Atypical Data'</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">6</span>))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>axs <span class="op">=</span> axs.ravel()</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(df.columns):</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>  bp <span class="op">=</span> axs[i].boxplot(df[col], vert<span class="op">=</span><span class="va">False</span>, flierprops<span class="op">=</span>fliers, showmeans<span class="op">=</span><span class="va">True</span>, meanprops<span class="op">=</span>mean_)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  axs[i].legend(handles<span class="op">=</span>[mean_artist, ad_artist], loc<span class="op">=</span><span class="st">'upper left'</span>, fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  axs[i].set_title(col_titles[i])</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The analysis conducted shows that both in the histograms and box plots, the batting average and on-base percentage variables are skewed to the left, while the triples, errors, and stolen bases variables are skewed to the right, and these same three variables have the most atypical data. It can also be observed that the batting average and on-base percentage variables have a small standard deviation due to the size of the whiskers. Finally, for most variables, the median and mean have similar values.</p>
<p>Correlation</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> df.corr()</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> corr_matrix.rename(columns<span class="op">=</span><span class="bu">dict</span>(<span class="bu">zip</span>(corr_matrix.columns, col_titles)))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> corr_matrix.rename(index<span class="op">=</span><span class="bu">dict</span>(<span class="bu">zip</span>(corr_matrix.index, col_titles)))</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr_matrix, square<span class="op">=</span><span class="va">True</span>, annot<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>ax)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The correlation matrix shows that several variables have high correlation coefficients (such as 0.89, 0.84, and 0.8). Therefore, it is important to exercise caution when dealing with variables that have a high degree of correlation, as they can have a significant impact on the model results.</p>
<section id="linear-regression-model" class="level1">
<h1>Linear Regression Model</h1>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> shapiro</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.diagnostic <span class="im">import</span> het_breuschpagan</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> checkModelAssumptions(model):</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    residuos <span class="op">=</span> model.resid</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#QQ plot</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    sm.qqplot(residuos, line<span class="op">=</span><span class="st">'45'</span>, ax<span class="op">=</span>axs[<span class="dv">0</span>,<span class="dv">0</span>])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>,<span class="dv">0</span>].set_title(<span class="st">'Residuals Q-Q plot'</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Residuals Histogram</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>,<span class="dv">1</span>].hist(residuos, bins<span class="op">=</span><span class="dv">30</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>,<span class="dv">1</span>].set_xlabel(<span class="st">'Residuos'</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>,<span class="dv">1</span>].set_ylabel(<span class="st">'Frecuencia'</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>,<span class="dv">1</span>].set_title(<span class="st">'Residuals Histogram'</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Reiduals Boxplot</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>,<span class="dv">0</span>].boxplot(residuos)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>,<span class="dv">0</span>].set_ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>,<span class="dv">0</span>].set_title(<span class="st">'Residuals Boxplot'</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Residuals</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>,<span class="dv">1</span>].scatter(model.fittedvalues, model.resid_pearson)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>,<span class="dv">1</span>].plot([<span class="bu">min</span>(model.fittedvalues), <span class="bu">max</span>(model.fittedvalues)], [<span class="dv">0</span>, <span class="dv">0</span>], <span class="st">'k--'</span>, lw<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>,<span class="dv">1</span>].set_xlabel(<span class="st">'Fitted Values'</span>)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>,<span class="dv">1</span>].set_ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>,<span class="dv">1</span>].set_title(<span class="st">' Standarized Residuals'</span>)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Normality test</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'================= Normality test ================='</span>)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>    stat, p <span class="op">=</span> shapiro(residuos)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Estadística de prueba:'</span>, stat)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Valor p:'</span>, p)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> p <span class="op">&lt;=</span> <span class="fl">0.05</span>: <span class="bu">print</span>(<span class="st">"Se rechaza H0"</span>)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"No se rechaza H0"</span>)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Homoscedasticity test</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'================= Homoscedasticity test ================='</span>)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>    lm, lm_pvalue, fvalue, f_pvalue <span class="op">=</span> het_breuschpagan(residuos, model.model.exog)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Lagrange multiplier statistic:'</span>, lm)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'p-value'</span>, lm_pvalue)</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'F value:'</span>, fvalue)</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'F p-value'</span>, f_pvalue)</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> lm_pvalue <span class="op">&lt;=</span> <span class="fl">0.05</span>: <span class="bu">print</span>(<span class="st">"Se rechaza H0"</span>)</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"No se rechaza H0"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Dataset split into train and test</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Agregando una columna de unos para el intercepto</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> sm.add_constant(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>                                                    df[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting the regression model</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>complete_model <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(complete_model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.509
Model:                            OLS   Adj. R-squared:                  0.445
Method:                 Least Squares   F-statistic:                     7.935
Date:                Thu, 04 May 2023   Prob (F-statistic):           5.68e-10
Time:                        21:52:53   Log-Likelihood:                -858.10
No. Observations:                 105   AIC:                             1742.
Df Residuals:                      92   BIC:                             1777.
Df Model:                          12                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const         610.4817    825.541      0.739      0.461   -1029.113    2250.077
batting      2222.3302   1.14e+04      0.195      0.846   -2.05e+04    2.49e+04
OBP         -1638.8541   8744.203     -0.187      0.852    -1.9e+04    1.57e+04
runs            7.3625     16.456      0.447      0.656     -25.321      40.046
hits            0.7794      9.802      0.080      0.937     -18.689      20.248
dooubles      -15.8879     19.852     -0.800      0.426     -55.316      23.541
tripes        -28.0621     51.604     -0.544      0.588    -130.552      74.428
homeruns       16.9401     28.594      0.592      0.555     -39.851      73.731
RBI            23.4869     12.224      1.921      0.058      -0.791      47.765
walks           2.7735     13.770      0.201      0.841     -24.575      30.122
strikeouts     -4.6099      4.667     -0.988      0.326     -13.879       4.659
stolenbases    14.9283     12.222      1.221      0.225      -9.345      39.202
errors        -19.7701     16.648     -1.188      0.238     -52.835      13.295
==============================================================================
Omnibus:                       12.536   Durbin-Watson:                   1.979
Prob(Omnibus):                  0.002   Jarque-Bera (JB):               13.938
Skew:                           0.715   Prob(JB):                     0.000941
Kurtosis:                       4.067   Cond. No.                     2.73e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.73e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Coefficients LR'</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(complete_model.params)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Coefficients LR
const           610.481682
batting        2222.330221
OBP           -1638.854103
runs              7.362492
hits              0.779417
dooubles        -15.887854
tripes          -28.062148
homeruns         16.940114
RBI              23.486874
walks             2.773515
strikeouts       -4.609948
stolenbases      14.928319
errors          -19.770148
dtype: float64</code></pre>
</div>
</div>
<p>Significant variables for the model</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p-values variables'</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(complete_model.pvalues)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>p-values variables
const          0.461490
batting        0.846156
OBP            0.851743
runs           0.655638
hits           0.936797
dooubles       0.425598
tripes         0.587896
homeruns       0.555018
RBI            0.057780
walks          0.840817
strikeouts     0.325847
stolenbases    0.225035
errors         0.238081
dtype: float64</code></pre>
</div>
</div>
<p>Metrics to check the model</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> complete_model.predict(X_test)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 472509.2342122604</code></pre>
</div>
</div>
<p>Check model assumptions:</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>checkModelAssumptions(complete_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>================= Normality test =================
Estadística de prueba: 0.9682337641716003
Valor p: 0.012694088742136955
Se rechaza H0
================= Homoscedasticity test =================
Lagrange multiplier statistic: 20.006687347370598
p-value 0.06695956645196854
F value: 1.8046667227031863
F p-value 0.05864618246295086
No se rechaza H0</code></pre>
</div>
</div>
<p>The linear regression model of all variables has an adjusted R-squared of 0.445, suggesting that approximately 44.5% of the variability of the response variable (salary) can be explained by the predictor variables included in the model.</p>
<p>Some of the regression coefficients have high p-values, suggesting that they are not statistically significant. For example, the coefficient for “hits” has a p-value of 0.936797, suggesting that it is not a significant variable for predicting salary. In addition, the variable “RBI” has a marginally significant p-value (0.057780), suggesting that it may be an important variable, but further analysis is needed to confirm its significance.</p>
<p>Regarding the MSE, the obtained value indicates that there is high variance between the values predicted by the model and the actual values of the target variable. In other words, the model does not fit the data well and underperforms in the prediction task. This may occur because there are variables that are highly correlated, as evidenced by values of 0.89 and 0.84.</p>
<p>With respect to check the model assumptions since the null hypothesis is rejected in Shapiro Wilk test, the residuals are not from a normal distribution. It can also be verified that the QQ plot does not conform to a normal distribution. In homoscedasticity test, since H0 is not rejected, it means that errors have a constant variance in all observations and, therefore, there is no heteroscedasticity. Furthermore, it can be seen that the residuals are evenly and randomly distributed around zero.</p>
<section id="modelos-propuestos" class="level3">
<h3 class="anchored" data-anchor-id="modelos-propuestos">Modelos Propuestos:</h3>
<p>Selection of the best variables using a greedy approach. At each stage, this estimator chooses the best feature to add based on the cross-validation score of an estimator.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> SequentialFeatureSelector</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df.copy()</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df_copy.drop(<span class="st">'const'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df_copy.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>                                                    df_copy[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Model</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression().fit(X_train, y_train)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>sfs <span class="op">=</span> SequentialFeatureSelector(model, direction<span class="op">=</span><span class="st">'forward'</span>, n_features_to_select<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>sfs.fit(X_train, y_train)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Variables seleccionadas</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> X_train.columns[sfs.get_support()]</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Variables seleccionadas:"</span>, selected_features)</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenar el modelo con las variables seleccionadas</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>X_selected <span class="op">=</span> X_train.iloc[:, sfs.get_support()]</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>model_final <span class="op">=</span> LinearRegression().fit(X_selected, y_train)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>coef_dict <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(X_selected.columns, model_final.coef_))</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>coef_dict[<span class="st">'intercept'</span>] <span class="op">=</span> model_final.intercept_</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coef_dict)</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>y_pred_selected <span class="op">=</span> model_final.predict(X_test.iloc[:, sfs.get_support()])</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>mse_selected <span class="op">=</span> mean_squared_error(y_test, y_pred_selected)</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE del modelo con variables seleccionadas: </span><span class="sc">{</span>mse_selected<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Variables seleccionadas: Index(['runs', 'tripes', 'homeruns'], dtype='object')
{'runs': 21.996696479214034, 'tripes': -57.43388406557736, 'homeruns': 32.45593597987061, 'intercept': 578.0977492624365}
MSE del modelo con variables seleccionadas: 500367.14098529215</code></pre>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>residuos <span class="op">=</span> y_test <span class="op">-</span> y_pred_selected</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Normality test</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'================= Normality test ================='</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>stat, p <span class="op">=</span> shapiro(residuos)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Estadística de prueba:'</span>, stat)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Valor p:'</span>, p)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> p <span class="op">&lt;=</span> <span class="fl">0.05</span>: <span class="bu">print</span>(<span class="st">"Se rechaza H0"</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"No se rechaza H0"</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Homoscedasticity test</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'================= Homoscedasticity test ================='</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>lm, lm_pvalue, fvalue, f_pvalue <span class="op">=</span> het_breuschpagan(residuos, X_test)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Lagrange multiplier statistic:'</span>, lm)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p-value'</span>, lm_pvalue)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'F value:'</span>, fvalue)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'F p-value'</span>, f_pvalue)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> lm_pvalue <span class="op">&lt;=</span> <span class="fl">0.05</span>: <span class="bu">print</span>(<span class="st">"Se rechaza H0"</span>)</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"No se rechaza H0"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>================= Normality test =================
Estadística de prueba: 0.9774359464645386
Valor p: 0.8004268407821655
No se rechaza H0
================= Homoscedasticity test =================
Lagrange multiplier statistic: 13.2369982289926
p-value 0.2781180219840999
F value: 1.2022266698458488
F p-value 0.36262790015504376
No se rechaza H0</code></pre>
</div>
</div>
<p>For both tests (homoscedasticity and normality) H0 is not rejected, so the residuals come from a normal distribution and have constant variance.</p>
<p>Model removing pairs of variables with high correlation, hits-runs (0.89)</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df.copy()</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df_copy.drop([<span class="st">'hits'</span>, <span class="st">'runs'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df_copy.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>                                                    df_copy[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model2.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.507
Model:                            OLS   Adj. R-squared:                  0.454
Method:                 Least Squares   F-statistic:                     9.664
Date:                Thu, 04 May 2023   Prob (F-statistic):           6.62e-11
Time:                        21:52:54   Log-Likelihood:                -858.28
No. Observations:                 105   AIC:                             1739.
Df Residuals:                      94   BIC:                             1768.
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const         563.4073    805.423      0.700      0.486   -1035.778    2162.593
batting      5140.0797   7691.127      0.668      0.506   -1.01e+04    2.04e+04
OBP         -3691.6341   6589.876     -0.560      0.577   -1.68e+04    9392.719
dooubles      -12.4389     17.454     -0.713      0.478     -47.094      22.216
tripes        -14.8323     45.047     -0.329      0.743    -104.274      74.609
homeruns       21.4989     23.591      0.911      0.364     -25.342      68.339
RBI            24.3652     11.277      2.161      0.033       1.974      46.756
walks           8.0549      9.709      0.830      0.409     -11.223      27.333
strikeouts     -4.7943      4.427     -1.083      0.282     -13.585       3.997
stolenbases    19.5713      8.651      2.262      0.026       2.395      36.747
errors        -19.5004     16.334     -1.194      0.236     -51.932      12.931
==============================================================================
Omnibus:                       11.564   Durbin-Watson:                   1.947
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               12.487
Skew:                           0.685   Prob(JB):                      0.00194
Kurtosis:                       3.989   Cond. No.                     1.24e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.24e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model2.predict(X_test)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 488929.61951423663</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>checkModelAssumptions(model2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>================= Normality test =================
Estadística de prueba: 0.9707664251327515
Valor p: 0.020151201635599136
Se rechaza H0
================= Homoscedasticity test =================
Lagrange multiplier statistic: 17.43924721889783
p-value 0.0651922403237696
F value: 1.872173532672274
F p-value 0.05877063885495448
No se rechaza H0</code></pre>
</div>
</div>
<p>The linear regression model has an adjusted R-squared of 0.454, suggesting that approximately 45.4% of the variability of the response variable (salary) can be explained by the predictor variables included in the model.</p>
<p>The MSE is slightly higher than the full model.</p>
<p>Since the null hypothesis is rejected in Shapiro Wilk test, the residuals are not from a normal distribution. In homoscedasticity test, since H0 is not rejected, it means that errors have a constant variance in all observations and, therefore, there is no heteroscedasticity. Furthermore, it can be seen that the residuals are evenly and randomly distributed around zero.</p>
<p>Model removing pairs of variables with high correlation, hits-runs (0.89) and doubles-homeruns (0.84)</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df.copy()</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df_copy.drop([<span class="st">'hits'</span>, <span class="st">'runs'</span>, <span class="st">'dooubles'</span>, <span class="st">'homeruns'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df_copy.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>                                                    df_copy[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model3.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.500
Model:                            OLS   Adj. R-squared:                  0.458
Method:                 Least Squares   F-statistic:                     11.98
Date:                Thu, 04 May 2023   Prob (F-statistic):           1.03e-11
Time:                        21:52:55   Log-Likelihood:                -859.06
No. Observations:                 105   AIC:                             1736.
Df Residuals:                      96   BIC:                             1760.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const         510.0526    797.551      0.640      0.524   -1073.074    2093.179
batting      1469.4215   7021.885      0.209      0.835   -1.25e+04    1.54e+04
OBP         -1149.4606   6208.703     -0.185      0.854   -1.35e+04    1.12e+04
tripes        -25.7709     43.824     -0.588      0.558    -112.761      61.219
RBI            28.8328      6.412      4.496      0.000      16.104      41.561
walks           4.6577      9.150      0.509      0.612     -13.505      22.820
strikeouts     -2.9994      4.041     -0.742      0.460     -11.022       5.023
stolenbases    20.0057      8.558      2.338      0.021       3.018      36.993
errors        -18.9731     16.184     -1.172      0.244     -51.098      13.152
==============================================================================
Omnibus:                        8.148   Durbin-Watson:                   1.956
Prob(Omnibus):                  0.017   Jarque-Bera (JB):                7.774
Skew:                           0.603   Prob(JB):                       0.0205
Kurtosis:                       3.566   Cond. No.                     1.12e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.12e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model3.predict(X_test)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 451816.86700758204</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>checkModelAssumptions(model3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>================= Normality test =================
Estadística de prueba: 0.9753574132919312
Valor p: 0.047396767884492874
Se rechaza H0
================= Homoscedasticity test =================
Lagrange multiplier statistic: 9.749838928412233
p-value 0.2830248338272729
F value: 1.2283240870638925
F p-value 0.2909760480199131
No se rechaza H0</code></pre>
</div>
</div>
<p>The linear regression model has an adjusted R-squared of 0.458, suggesting that approximately 45.8% of the variability of the response variable (salary) can be explained by the predictor variables included in the model.</p>
<p>In terms of the MSE, it has a lower MSE than the full model, which indicates that this model fits the data better, although the MSE is still high.</p>
<p>Since the null hypothesis is rejected in Shapiro Wilk test, the residuals are not from a normal distribution. In homoscedasticity test, since H0 is not rejected, it means that errors have a constant variance in all observations and, therefore, there is no heteroscedasticity. Furthermore, it can be seen that the residuals are evenly and randomly distributed around zero.</p>
<p>Model removing pairs of variables with high correlations, hits-runs (0.89) and OBP-batting (0.8)</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df.copy()</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df_copy.drop([<span class="st">'hits'</span>, <span class="st">'runs'</span>, <span class="st">'OBP'</span>, <span class="st">'batting'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df_copy.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>                                                    df_copy[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>model4 <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model4.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.505
Model:                            OLS   Adj. R-squared:                  0.463
Method:                 Least Squares   F-statistic:                     12.22
Date:                Thu, 04 May 2023   Prob (F-statistic):           6.53e-12
Time:                        21:52:56   Log-Likelihood:                -858.53
No. Observations:                 105   AIC:                             1735.
Df Residuals:                      96   BIC:                             1759.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const         643.0386    265.933      2.418      0.017     115.167    1170.911
dooubles       -9.5105     16.723     -0.569      0.571     -42.706      23.685
tripes         -7.5679     43.311     -0.175      0.862     -93.540      78.404
homeruns       16.4791     22.207      0.742      0.460     -27.602      60.560
RBI            28.2745      9.593      2.947      0.004       9.233      47.316
walks           3.6807      5.216      0.706      0.482      -6.672      14.034
strikeouts     -5.2118      4.193     -1.243      0.217     -13.535       3.111
stolenbases    21.4778      8.106      2.650      0.009       5.388      37.568
errors        -18.2242     16.094     -1.132      0.260     -50.170      13.722
==============================================================================
Omnibus:                       10.198   Durbin-Watson:                   1.960
Prob(Omnibus):                  0.006   Jarque-Bera (JB):               10.555
Skew:                           0.641   Prob(JB):                      0.00510
Kurtosis:                       3.878   Cond. No.                         337.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model4.predict(X_test)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 496001.73702509375</code></pre>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>checkModelAssumptions(model4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-28-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>================= Normality test =================
Estadística de prueba: 0.9727652072906494
Valor p: 0.029171880334615707
Se rechaza H0
================= Homoscedasticity test =================
Lagrange multiplier statistic: 16.493149514567264
p-value 0.03584156289911877
F value: 2.2361861606111755
F p-value 0.031107792256653357
Se rechaza H0</code></pre>
</div>
</div>
<p>The linear regression model has an adjusted R-squared of 0.463, suggesting that approximately 46.3% of the variability of the response variable (salary) can be explained by the predictor variables included in the model.</p>
<p>The MSE is slightly higher than the full model.</p>
<p>Since the null hypothesis is rejected in Shapiro Wilk test, the residuals are not from a normal distribution. In homoscedasticity test, since H0 is rejected, it means that there is sufficient evidence to conclude that the variance of the errors is not constant and, therefore, that there is heteroscedasticity in the model.</p>
<p>Model removing the variables with the highest p-value from the complete model:</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df.copy()</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>df_copy <span class="op">=</span> df_copy.drop([<span class="st">'hits'</span>, <span class="st">'walks'</span>, <span class="st">'OBP'</span>, <span class="st">'batting'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(df_copy.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), </span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>                                                    df_copy[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>model5 <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model5.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 salary   R-squared:                       0.508
Model:                            OLS   Adj. R-squared:                  0.467
Method:                 Least Squares   F-statistic:                     12.39
Date:                Thu, 04 May 2023   Prob (F-statistic):           4.74e-12
Time:                        21:52:57   Log-Likelihood:                -858.16
No. Observations:                 105   AIC:                             1734.
Df Residuals:                      96   BIC:                             1758.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const         638.8948    264.001      2.420      0.017     114.856    1162.933
runs           10.0074      9.188      1.089      0.279      -8.232      28.246
dooubles      -14.7123     16.905     -0.870      0.386     -48.269      18.844
tripes        -28.5430     46.473     -0.614      0.541    -120.792      63.706
homeruns       12.4897     21.779      0.573      0.568     -30.740      55.720
RBI            25.3140     10.201      2.481      0.015       5.065      45.563
strikeouts     -4.6401      3.924     -1.183      0.240     -12.429       3.149
stolenbases    14.4213     11.271      1.279      0.204      -7.952      36.795
errors        -19.0235     15.935     -1.194      0.235     -50.654      12.607
==============================================================================
Omnibus:                       11.750   Durbin-Watson:                   1.992
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               12.680
Skew:                           0.696   Prob(JB):                      0.00176
Kurtosis:                       3.979   Cond. No.                         350.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model5.predict(X_test)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 465509.7083045767</code></pre>
</div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>checkModelAssumptions(model5)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>================= Normality test =================
Estadística de prueba: 0.969240665435791
Valor p: 0.015239850617945194
Se rechaza H0
================= Homoscedasticity test =================
Lagrange multiplier statistic: 13.810639655586295
p-value 0.08683650570051278
F value: 1.8174014516726242
F p-value 0.08300775391851146
No se rechaza H0</code></pre>
</div>
</div>
<p>The linear regression model has an adjusted R-squared of 0.467, suggesting that approximately 46.7% of the variability of the response variable (salary) can be explained by the predictor variables included in the model.</p>
<p>In terms of the MSE, it has a lower MSE than the full model, which indicates that this model fits the data better, although the MSE is still high.</p>
<p>Since the null hypothesis is rejected in Shapiro Wilk test, the residuals are not from a normal distribution. In homoscedasticity test, since H0 is not rejected, it means that errors have a constant variance in all observations and, therefore, there is no heteroscedasticity. Furthermore, it can be seen that the residuals are evenly and randomly distributed around zero.</p>
<p>Model considering a PCA analysis:</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>pca.fit(df.drop([<span class="st">'salary'</span>], axis<span class="op">=</span><span class="dv">1</span>)) </span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(df.drop([<span class="st">'salary'</span>], axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>expl <span class="op">=</span> pca.explained_variance_ratio_</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'suma:'</span>,<span class="bu">sum</span>(expl[<span class="dv">0</span>:<span class="dv">5</span>]))</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>plt.plot(np.cumsum(pca.explained_variance_ratio_))</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'number of components'</span>)</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="dv">0</span>, df.shape[<span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span>, <span class="fl">1.0</span>))</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'cumulative explained variance'</span>)</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>suma: 0.982670851047459</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-32-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>X_pca_df <span class="op">=</span> pd.DataFrame(X_pca[:, :<span class="dv">4</span>], columns<span class="op">=</span>[<span class="st">'PC1'</span>, <span class="st">'PC2'</span>, <span class="st">'PC3'</span>, <span class="st">'PC4'</span>])</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>X_pca_df[<span class="st">'salary'</span>] <span class="op">=</span> df[<span class="st">'salary'</span>]</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_pca_df.drop(<span class="st">'salary'</span>, axis<span class="op">=</span><span class="dv">1</span>), X_pca_df[<span class="st">'salary'</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>model_pca <span class="op">=</span> sm.OLS(y_train, X_train).fit()</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_pca.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                                 OLS Regression Results                                
=======================================================================================
Dep. Variable:                 salary   R-squared (uncentered):                   0.115
Model:                            OLS   Adj. R-squared (uncentered):              0.080
Method:                 Least Squares   F-statistic:                              3.290
Date:                Thu, 04 May 2023   Prob (F-statistic):                      0.0140
Time:                        21:52:59   Log-Likelihood:                         -960.59
No. Observations:                 105   AIC:                                      1929.
Df Residuals:                     101   BIC:                                      1940.
Df Model:                           4                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
PC1          -11.4914      3.471     -3.310      0.001     -18.378      -4.605
PC2            6.5527      7.868      0.833      0.407      -9.055      22.161
PC3            3.5005     11.626      0.301      0.764     -19.563      26.564
PC4          -18.0457     14.852     -1.215      0.227     -47.509      11.418
==============================================================================
Omnibus:                        5.126   Durbin-Watson:                   0.345
Prob(Omnibus):                  0.077   Jarque-Bera (JB):                5.197
Skew:                           0.519   Prob(JB):                       0.0744
Kurtosis:                       2.666   Cond. No.                         4.28
==============================================================================

Notes:
[1] R² is computed without centering (uncentered) since the model does not contain a constant.
[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model_pca.predict(X_test)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_test_pred)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MSE for the LR Model: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE for the LR Model: 6201010.128683986</code></pre>
</div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>checkModelAssumptions(model_pca)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-35-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>================= Normality test =================
Estadística de prueba: 0.9687559008598328
Valor p: 0.01395378913730383
Se rechaza H0
================= Homoscedasticity test =================
Lagrange multiplier statistic: 0.560316256152173
p-value 0.9054538482628012
F value: 0.13546561001220836
F p-value 0.9688985303512637
No se rechaza H0</code></pre>
</div>
</div>
<p>The linear regression model has an adjusted R-squared of 0.08, suggesting that approximately 8% of the variability of the response variable (salary) can be explained by the predictor variables included in the model.</p>
<p>In terms of MSE it is the worst of all, we can see how it shoots up abruptly. The model does not fit the data</p>
<p>Since the null hypothesis is rejected in Shapiro Wilk test, the residuals are not from a normal distribution. In homoscedasticity test, since H0 is not rejected, it means that errors have a constant variance in all observations and, therefore, there is no heteroscedasticity. Although the residuals have a random distribution, the residuals have a positive trend relative to the fitted values, this could indicate that the model is not capturing a nonlinear relationship between the predictor variables and the response variable</p>
</section>
<section id="resumen-de-resultados" class="level3">
<h3 class="anchored" data-anchor-id="resumen-de-resultados">RESUMEN DE RESULTADOS</h3>
<table class="table">
<thead>
<tr class="header">
<th>Modelo</th>
<th>MSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Modelo 2 elimnado correlaciones</td>
<td>451,816.87</td>
</tr>
<tr class="even">
<td>Modelo sin p-values grandes</td>
<td>465,509.71</td>
</tr>
<tr class="odd">
<td>Modelo Completo</td>
<td>472,509.23</td>
</tr>
<tr class="even">
<td>Modelo 1 elimnado correlaciones</td>
<td>488,929.62</td>
</tr>
<tr class="odd">
<td>Modelo 3 elimnado correlaciones</td>
<td>496,001.74</td>
</tr>
<tr class="even">
<td>Modelo Greedy</td>
<td>500,367.14</td>
</tr>
<tr class="odd">
<td>Modelo PCA</td>
<td>6,201,010.12</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="punto-2" class="level1">
<h1>Punto 2</h1>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_csv(<span class="st">'fertility.csv'</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df2.drop([<span class="st">'voc_train'</span>, <span class="st">'german'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>dim_df <span class="op">=</span> df2.shape</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The dataset consists of </span><span class="sc">{</span>dim_df[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> rows and </span><span class="sc">{</span>dim_df[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> columns"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The dataset consists of 1243 rows and 7 columns</code></pre>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>df2.isnull().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>children        0
years_school    0
university      0
religion        0
year_birth      0
rural           0
age_marriage    0
dtype: int64</code></pre>
</div>
</div>
<p>Convert cathegorical data to numerical</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>categorical_vars <span class="op">=</span> [<span class="st">'university'</span>, <span class="st">'religion'</span>, <span class="st">'rural'</span>]</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> var <span class="kw">in</span> categorical_vars:</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>    df2[var] <span class="op">=</span> le.fit_transform(df2[var])</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>df2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">children</th>
<th data-quarto-table-cell-role="th">years_school</th>
<th data-quarto-table-cell-role="th">university</th>
<th data-quarto-table-cell-role="th">religion</th>
<th data-quarto-table-cell-role="th">year_birth</th>
<th data-quarto-table-cell-role="th">rural</th>
<th data-quarto-table-cell-role="th">age_marriage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2</td>
<td>8</td>
<td>0</td>
<td>0</td>
<td>42</td>
<td>1</td>
<td>20</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>3</td>
<td>8</td>
<td>0</td>
<td>0</td>
<td>55</td>
<td>1</td>
<td>21</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2</td>
<td>8</td>
<td>0</td>
<td>0</td>
<td>51</td>
<td>1</td>
<td>24</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>8</td>
<td>0</td>
<td>0</td>
<td>54</td>
<td>0</td>
<td>26</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2</td>
<td>8</td>
<td>0</td>
<td>0</td>
<td>46</td>
<td>1</td>
<td>22</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1238</td>
<td>2</td>
<td>13</td>
<td>1</td>
<td>1</td>
<td>45</td>
<td>1</td>
<td>23</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1239</td>
<td>2</td>
<td>13</td>
<td>1</td>
<td>1</td>
<td>41</td>
<td>0</td>
<td>25</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1240</td>
<td>2</td>
<td>13</td>
<td>1</td>
<td>1</td>
<td>56</td>
<td>0</td>
<td>25</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1241</td>
<td>2</td>
<td>13</td>
<td>1</td>
<td>1</td>
<td>58</td>
<td>0</td>
<td>25</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1242</td>
<td>0</td>
<td>12</td>
<td>1</td>
<td>1</td>
<td>44</td>
<td>0</td>
<td>24</td>
</tr>
</tbody>
</table>

<p>1243 rows × 7 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> df2.drop(<span class="st">'children'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> df2[<span class="st">'children'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="poisson-model" class="level3">
<h3 class="anchored" data-anchor-id="poisson-model">Poisson Model</h3>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>model_poisson <span class="op">=</span> sm.GLM(y_train, X_train, family<span class="op">=</span>sm.families.Poisson()).fit()</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_poisson.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:               children   No. Observations:                 1243
Model:                            GLM   Df Residuals:                     1237
Model Family:                 Poisson   Df Model:                            5
Link Function:                    Log   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -2209.3
Date:                Thu, 04 May 2023   Deviance:                       1249.3
Time:                        21:53:00   Pearson chi2:                 1.30e+03
No. Iterations:                     4   Pseudo R-squ. (CS):           -0.03683
Covariance Type:            nonrobust                                         
================================================================================
                   coef    std err          z      P&gt;|z|      [0.025      0.975]
--------------------------------------------------------------------------------
years_school     0.0873      0.016      5.543      0.000       0.056       0.118
university      -0.3336      0.128     -2.599      0.009      -0.585      -0.082
religion        -0.0265      0.017     -1.551      0.121      -0.060       0.007
year_birth       0.0059      0.002      2.747      0.006       0.002       0.010
rural            0.1171      0.037      3.151      0.002       0.044       0.190
age_marriage    -0.0111      0.006     -1.836      0.066      -0.023       0.001
================================================================================</code></pre>
</div>
</div>
<p>As shown in the table, all variables except “religion” and “age_marriage” have p-values less than 0.05, indicating that they are statistically significant in the model. However, since the p-values of “religion” and “age_marriage” are 0.119 &gt; 0.05 and 0.066 &gt; 0.05, respectively, it cannot be concluded that these variables have a significant effect on the model.</p>
<p>The negative coefficient of “university”, as a binary categorical variable (yes/no), suggests that women with this characteristic (i.e., a “yes”) have fewer children.</p>
<p>On the other hand, the positive coefficient of “rural” suggests that women with this characteristic have more children.</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>sm.qqplot(model_poisson.resid_response, line<span class="op">=</span><span class="st">'s'</span>)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'QQ-plot de los residuos'</span>)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-41-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Normality test</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'================= Normality test ================='</span>)</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>stat, p <span class="op">=</span> shapiro(model_poisson.resid_response)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Estadística de prueba:'</span>, stat)</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Valor p:'</span>, p)</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> p <span class="op">&lt;=</span> <span class="fl">0.05</span>: <span class="bu">print</span>(<span class="st">"Se rechaza H0"</span>)</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"No se rechaza H0"</span>)</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Homoscedasticity test</span></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'================= Homoscedasticity test ================='</span>)</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>lm, lm_pvalue, fvalue, f_pvalue <span class="op">=</span> het_breuschpagan(model_poisson.resid_response, model_poisson.model.exog)</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Lagrange multiplier statistic:'</span>, lm)</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p-value'</span>, lm_pvalue)</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'F value:'</span>, fvalue)</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'F p-value'</span>, f_pvalue)</span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> lm_pvalue <span class="op">&lt;=</span> <span class="fl">0.05</span>: <span class="bu">print</span>(<span class="st">"Se rechaza H0"</span>)</span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"No se rechaza H0"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>================= Normality test =================
Estadística de prueba: 0.9120537042617798
Valor p: 3.2358870953963777e-26
Se rechaza H0
================= Homoscedasticity test =================
Lagrange multiplier statistic: 188.88336755534738
p-value 6.768409554756128e-39
F value: 36.94226338820761
F p-value 2.405853980184044e-41
Se rechaza H0</code></pre>
</div>
</div>
</section>
<section id="negative-binomial-model" class="level3">
<h3 class="anchored" data-anchor-id="negative-binomial-model">Negative Binomial Model</h3>
<p>Si la razón entre el Chi-cuadrado y los grados de libertad es mayor a 1, entonces existe sobredispersión.</p>
<p>En este caso, el Pearson Chi-cuadrado es de 1300, con 1237 grados de libertad, lo que resulta en una razón de 1.0509. Como esta razón es mayor a 1, se puede concluir que los datos presentan sobredispersión.</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>model_nb <span class="op">=</span> sm.GLM(y_train, X_train, family<span class="op">=</span>sm.families.NegativeBinomial()).fit()</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_nb.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:               children   No. Observations:                 1243
Model:                            GLM   Df Residuals:                     1237
Model Family:        NegativeBinomial   Df Model:                            5
Link Function:                    Log   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -2560.0
Date:                Thu, 04 May 2023   Deviance:                       429.50
Time:                        21:53:00   Pearson chi2:                     389.
No. Iterations:                     6   Pseudo R-squ. (CS):           -0.01113
Covariance Type:            nonrobust                                         
================================================================================
                   coef    std err          z      P&gt;|z|      [0.025      0.975]
--------------------------------------------------------------------------------
years_school     0.0877      0.029      2.991      0.003       0.030       0.145
university      -0.3324      0.227     -1.464      0.143      -0.777       0.113
religion        -0.0272      0.031     -0.867      0.386      -0.089       0.034
year_birth       0.0061      0.004      1.511      0.131      -0.002       0.014
rural            0.1100      0.068      1.620      0.105      -0.023       0.243
age_marriage    -0.0109      0.011     -0.985      0.325      -0.033       0.011
================================================================================</code></pre>
</div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>sm.qqplot(model_nb.resid_response, line<span class="op">=</span><span class="st">'s'</span>)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'QQ-plot'</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-44-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Normality test</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'================= Normality test ================='</span>)</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>stat, p <span class="op">=</span> shapiro(model_nb.resid_response)</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Estadística de prueba:'</span>, stat)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Valor p:'</span>, p)</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> p <span class="op">&lt;=</span> <span class="fl">0.05</span>: <span class="bu">print</span>(<span class="st">"Se rechaza H0"</span>)</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"No se rechaza H0"</span>)</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Homoscedasticity test</span></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'================= Homoscedasticity test ================='</span>)</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>lm, lm_pvalue, fvalue, f_pvalue <span class="op">=</span> het_breuschpagan(model_nb.resid_response, model_nb.model.exog)</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Lagrange multiplier statistic:'</span>, lm)</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p-value'</span>, lm_pvalue)</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'F value:'</span>, fvalue)</span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'F p-value'</span>, f_pvalue)</span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> lm_pvalue <span class="op">&lt;=</span> <span class="fl">0.05</span>: <span class="bu">print</span>(<span class="st">"Se rechaza H0"</span>)</span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"No se rechaza H0"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>================= Normality test =================
Estadística de prueba: 0.9120210409164429
Valor p: 3.204120036521677e-26
Se rechaza H0
================= Homoscedasticity test =================
Lagrange multiplier statistic: 191.3934268601782
p-value 1.967633235667284e-39
F value: 37.52253537162605
F p-value 5.6524421742167544e-42
Se rechaza H0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>resid_poisson <span class="op">=</span> model_poisson.resid_response</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>resid_nb <span class="op">=</span> model_nb.resid_response</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(model_nb.fittedvalues, resid_nb, label<span class="op">=</span><span class="st">'NB'</span>)</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(model_poisson.fittedvalues, resid_poisson, label<span class="op">=</span><span class="st">'Poisson'</span>)</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Fitted Values'</span>)</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="taller3_files/figure-html/cell-46-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>To compare the 2 models we will use the AIC (Akaike Information Criterion), which is a model selection criterion that seeks to balance the complexity of the model with its ability to fit the data. The AIC is calculated from the logarithm of the model’s likelihood function and its complexity. The lower the AIC value, the better the model fits the data.</p>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># AIC y BIC del modelo Poisson</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>poisson_aic <span class="op">=</span> model_poisson.aic</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>nb_aic <span class="op">=</span> model_nb.aic</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"AIC Poisson:"</span>, poisson_aic)</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"AIC Binomial Negativo:"</span>, nb_aic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>AIC Poisson: 4430.502787480056
AIC Binomial Negativo: 5132.092370301076</code></pre>
</div>
</div>
<p>Since the Poisson model has the lowest AIC, it is the model that best fits the data.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>